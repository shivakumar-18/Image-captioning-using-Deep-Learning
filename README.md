# Image-captioning-using-Deep-Learning
I used the Flicker8k dataset for this project.
The objective of the project is to predict the captions for the input image. 
The dataset consists of 8k images and 5 captions for each image. 
The features are extracted from both the image and the text captions for input. 
The features will be concatenated to predict the next word of the caption. 
CNN is used for images and LSTM is used for text. BLEU Score is used as a metric to evaluate the performance of the trained model.
